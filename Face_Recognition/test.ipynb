{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.applications import resnet\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from pyexcel.cookbook import merge_all_to_a_book\n",
    "# import pyexcel.ext.xlsx # no longer required if you use pyexcel >= 0.2.2 \n",
    "import glob\n",
    "\n",
    "def get_embedding_module(imageSize):\n",
    "    # construct the input layer and pass the inputs through a\n",
    "    # pre-processing layer\n",
    "    inputs = keras.Input(imageSize + (3,))\n",
    "    x = resnet.preprocess_input(inputs)\n",
    "\n",
    "    # fetch the pre-trained resnet 50 model and freeze the weights\n",
    "    baseCnn = resnet.ResNet50(weights=\"imagenet\", include_top=False)\n",
    "    baseCnn.trainable=False\n",
    "\n",
    "    # pass the pre-processed inputs through the base cnn and get the\n",
    "    # extracted features from the inputs\n",
    "    extractedFeatures = baseCnn(x)\n",
    "    # pass the extracted features through a number of trainable layers\n",
    "    x = layers.GlobalAveragePooling2D()(extractedFeatures)\n",
    "    x = layers.Dense(units=1024, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(units=256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(units=128)(x)\n",
    "    # build the embedding model and return it\n",
    "    embedding = keras.Model(inputs, outputs, name=\"embedding\")\n",
    "    return embedding\n",
    "\n",
    "def get_siamese_network(imageSize, embeddingModel):\n",
    "    # build the anchor, positive and negative input layer\n",
    "    anchorInput = keras.Input(name=\"anchor\", shape=imageSize + (3,))\n",
    "    positiveInput = keras.Input(name=\"positive\", shape=imageSize + (3,))\n",
    "    negativeInput = keras.Input(name=\"negative\", shape=imageSize + (3,))\n",
    "    # embed the anchor, positive and negative images\n",
    "    anchorEmbedding = embeddingModel(anchorInput)\n",
    "    positiveEmbedding = embeddingModel(positiveInput)\n",
    "    negativeEmbedding = embeddingModel(negativeInput)\n",
    "    # build the siamese network and return it\n",
    "    siamese_network = keras.Model(\n",
    "        inputs=[anchorInput, positiveInput, negativeInput],\n",
    "        outputs=[anchorEmbedding, positiveEmbedding, negativeEmbedding]\n",
    "    )\n",
    "    return siamese_network\n",
    "\n",
    "class SiameseModel(keras.Model):\n",
    "    def __init__(self, siameseNetwork, margin, lossTracker):\n",
    "        super().__init__()\n",
    "        self.siameseNetwork = siameseNetwork\n",
    "        self.margin = margin\n",
    "        self.lossTracker = lossTracker\n",
    "    def _compute_distance(self, inputs):\n",
    "        (anchor, positive, negative) = inputs\n",
    "        # embed the images using the siamese network\n",
    "        embeddings = self.siameseNetwork((anchor, positive, negative))\n",
    "        anchorEmbedding = embeddings[0]\n",
    "        positiveEmbedding = embeddings[1]\n",
    "        negativeEmbedding = embeddings[2]\n",
    "        # calculate the anchor to positive and negative distance\n",
    "        apDistance = tf.reduce_sum(\n",
    "            tf.square(anchorEmbedding - positiveEmbedding), axis=-1\n",
    "        )\n",
    "        anDistance = tf.reduce_sum(\n",
    "            tf.square(anchorEmbedding - negativeEmbedding), axis=-1\n",
    "        )\n",
    "\n",
    "        # return the distances\n",
    "        return (apDistance, anDistance)\n",
    "    def _compute_loss(self, apDistance, anDistance):\n",
    "        loss = apDistance - anDistance\n",
    "        loss = tf.maximum(loss + self.margin, 0.0)\n",
    "        return loss\n",
    "    def call(self, inputs):\n",
    "        # compute the distance between the anchor and positive,\n",
    "        # negative images\n",
    "        (apDistance, anDistance) = self._compute_distance(inputs)\n",
    "        return (apDistance, anDistance)\n",
    "    def train_step(self, inputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # compute the distance between the anchor and positive,\n",
    "            # negative images\n",
    "            (apDistance, anDistance) = self._compute_distance(inputs)\n",
    "            # calculate the loss of the siamese network\n",
    "            loss = self._compute_loss(apDistance, anDistance)\n",
    "        # compute the gradients and optimize the model\n",
    "        gradients = tape.gradient(\n",
    "            loss,\n",
    "            self.siameseNetwork.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siameseNetwork.trainable_variables)\n",
    "        )\n",
    "        # update the metrics and return the loss\n",
    "        self.lossTracker.update_state(loss)\n",
    "        return {\"loss\": self.lossTracker.result()}\n",
    "    def test_step(self, inputs):\n",
    "        # compute the distance between the anchor and positive,\n",
    "        # negative images\n",
    "        (apDistance, anDistance) = self._compute_distance(inputs)\n",
    "        # calculate the loss of the siamese network\n",
    "        loss = self._compute_loss(apDistance, anDistance)\n",
    "\n",
    "        # update the metrics and return the loss\n",
    "        self.lossTracker.update_state(loss)\n",
    "        return {\"loss\": self.lossTracker.result()}\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.lossTracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading the siamese network from siamese_network_collected_data_64...\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "['had.jpg', 'hosny.png', 'kimo.jpg', 'salah.jpg', 'ziad.jpg']\n",
      "['had', 'hosny', 'kimo', 'salah', 'ziad']\n",
      "[INFO] starting video stream...\n",
      "The disctance with had is: 1.9360756874084473\n",
      "The disctance with hosny is: 3.37654972076416\n",
      "The disctance with kimo is: 2.24184513092041\n",
      "The disctance with salah is: 0.5929044485092163\n",
      "The disctance with ziad is: 3.4123098850250244\n",
      "The disctance with had is: 0.418770432472229\n",
      "The disctance with hosny is: 0.741789698600769\n",
      "The disctance with kimo is: 0.5078322887420654\n",
      "The disctance with salah is: 0.16378182172775269\n",
      "The disctance with ziad is: 0.9137012958526611\n",
      "SALAH\n",
      "The disctance with had is: 0.9033197164535522\n",
      "The disctance with hosny is: 1.3682503700256348\n",
      "The disctance with kimo is: 0.7854717969894409\n",
      "The disctance with salah is: 0.11932060122489929\n",
      "The disctance with ziad is: 1.1738836765289307\n",
      "SALAH\n",
      "The disctance with had is: 1.296838402748108\n",
      "The disctance with hosny is: 1.408611536026001\n",
      "The disctance with kimo is: 1.3317145109176636\n",
      "The disctance with salah is: 0.0853251963853836\n",
      "The disctance with ziad is: 1.8841317892074585\n",
      "SALAH\n",
      "The disctance with had is: 1.3538901805877686\n",
      "The disctance with hosny is: 0.4694882035255432\n",
      "The disctance with kimo is: 1.2613654136657715\n",
      "The disctance with salah is: 0.45205193758010864\n",
      "The disctance with ziad is: 0.827237069606781\n",
      "SALAH\n",
      "The disctance with had is: 1.342210054397583\n",
      "The disctance with hosny is: 2.1144421100616455\n",
      "The disctance with kimo is: 1.397891879081726\n",
      "The disctance with salah is: 0.14330285787582397\n",
      "The disctance with ziad is: 2.2759995460510254\n",
      "SALAH\n",
      "The disctance with had is: 1.1190824508666992\n",
      "The disctance with hosny is: 0.922742486000061\n",
      "The disctance with kimo is: 1.0701686143875122\n",
      "The disctance with salah is: 0.0992727130651474\n",
      "The disctance with ziad is: 1.412262201309204\n",
      "SALAH\n",
      "The disctance with had is: 1.048818826675415\n",
      "The disctance with hosny is: 1.2687091827392578\n",
      "The disctance with kimo is: 1.0059926509857178\n",
      "The disctance with salah is: 0.0746336430311203\n",
      "The disctance with ziad is: 1.4688282012939453\n",
      "SALAH\n",
      "The disctance with had is: 1.582219123840332\n",
      "The disctance with hosny is: 2.090111494064331\n",
      "The disctance with kimo is: 1.5049233436584473\n",
      "The disctance with salah is: 0.4301286041736603\n",
      "The disctance with ziad is: 1.6209452152252197\n",
      "The disctance with had is: 1.935492753982544\n",
      "The disctance with hosny is: 1.7275147438049316\n",
      "The disctance with kimo is: 1.8531686067581177\n",
      "The disctance with salah is: 0.2901362180709839\n",
      "The disctance with ziad is: 2.1386704444885254\n",
      "The disctance with had is: 1.3135157823562622\n",
      "The disctance with hosny is: 1.5530762672424316\n",
      "The disctance with kimo is: 1.4015480279922485\n",
      "The disctance with salah is: 0.09111769497394562\n",
      "The disctance with ziad is: 1.9546295404434204\n",
      "SALAH\n",
      "The disctance with had is: 0.8786574602127075\n",
      "The disctance with hosny is: 1.0337451696395874\n",
      "The disctance with kimo is: 0.8634765148162842\n",
      "The disctance with salah is: 0.052831340581178665\n",
      "The disctance with ziad is: 1.4467363357543945\n",
      "SALAH\n",
      "The disctance with had is: 1.296542763710022\n",
      "The disctance with hosny is: 1.1333651542663574\n",
      "The disctance with kimo is: 1.365647554397583\n",
      "The disctance with salah is: 0.1607019156217575\n",
      "The disctance with ziad is: 1.4977158308029175\n",
      "SALAH\n",
      "The disctance with had is: 1.110426664352417\n",
      "The disctance with hosny is: 1.4780082702636719\n",
      "The disctance with kimo is: 1.1431550979614258\n",
      "The disctance with salah is: 0.07296635210514069\n",
      "The disctance with ziad is: 1.9928947687149048\n",
      "SALAH\n",
      "The disctance with had is: 1.1882038116455078\n",
      "The disctance with hosny is: 1.9553189277648926\n",
      "The disctance with kimo is: 1.2998510599136353\n",
      "The disctance with salah is: 0.10236603766679764\n",
      "The disctance with ziad is: 2.1959283351898193\n",
      "SALAH\n",
      "The disctance with had is: 1.0606274604797363\n",
      "The disctance with hosny is: 1.7676780223846436\n",
      "The disctance with kimo is: 1.1107858419418335\n",
      "The disctance with salah is: 0.06735303997993469\n",
      "The disctance with ziad is: 2.0585098266601562\n",
      "SALAH\n",
      "The disctance with had is: 0.6835650205612183\n",
      "The disctance with hosny is: 1.2379655838012695\n",
      "The disctance with kimo is: 0.8676681518554688\n",
      "The disctance with salah is: 0.060528919100761414\n",
      "The disctance with ziad is: 1.5044505596160889\n",
      "SALAH\n",
      "The disctance with had is: 1.0645549297332764\n",
      "The disctance with hosny is: 1.2670331001281738\n",
      "The disctance with kimo is: 0.964337944984436\n",
      "The disctance with salah is: 0.041668981313705444\n",
      "The disctance with ziad is: 1.5904370546340942\n",
      "SALAH\n",
      "The disctance with had is: 0.9057183861732483\n",
      "The disctance with hosny is: 0.747420608997345\n",
      "The disctance with kimo is: 0.881909966468811\n",
      "The disctance with salah is: 0.11515702307224274\n",
      "The disctance with ziad is: 1.123091459274292\n",
      "SALAH\n",
      "The disctance with had is: 1.6154705286026\n",
      "The disctance with hosny is: 0.9916912913322449\n",
      "The disctance with kimo is: 1.2115919589996338\n",
      "The disctance with salah is: 0.3666659891605377\n",
      "The disctance with ziad is: 1.4667319059371948\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from time import sleep\n",
    "from imutils.video import VideoStream\n",
    "import imutils\n",
    "\n",
    "IMAGES_PATH = 'ImageAttendance'\n",
    "MODEL_PATH = 'siamese_network_collected_data_64'\n",
    "CASCADE_PATH = 'haarcascade_frontalface_default.xml'\n",
    "THRESHOLD = 0.05\n",
    "\n",
    "# Show waiting screen\n",
    "waiting = np.zeros(500, np.uint8)\n",
    "cv2.imshow(\"WebCam\", waiting)\n",
    "\n",
    "# Load the model\n",
    "modelPath = MODEL_PATH\n",
    "print(f\"[INFO] loading the siamese network from {modelPath}...\")\n",
    "siameseNetwork = keras.models.load_model(filepath=modelPath)\n",
    "siameseModel = SiameseModel(\n",
    "\tsiameseNetwork=siameseNetwork,\n",
    "\tmargin=0.5,\n",
    "\tlossTracker=keras.metrics.Mean(name=\"loss\"),\n",
    ")\n",
    "\n",
    "# Load Har Cascade face detector\n",
    "detector = cv2.CascadeClassifier(CASCADE_PATH)\n",
    "\n",
    "# Find Face Position\n",
    "def find_faces(img):\n",
    "    \"\"\"\n",
    "    A Function to find faces position in @img\n",
    "\n",
    "    Args:\n",
    "        - img: an image\n",
    "    \"\"\"\n",
    "    gray_faces = []\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # detect faces in the grayscale frame\n",
    "    rects = detector.detectMultiScale(gray, scaleFactor=1.1, \n",
    "        minNeighbors=5, minSize=(30, 30))\n",
    "    # Reordering the image\n",
    "    for (x, y, w, h) in rects:\n",
    "        face = gray[y:y + h, x:x + w]\n",
    "        gray_face = np.zeros((*face.shape[:2],3), np.uint8)\n",
    "        # print(gray_face.shape, face.shape)\n",
    "        gray_face[:,:,0] = gray_face[:,:,1] = gray_face[:,:,2] = face[:,:]\n",
    "        \n",
    "        gray_face = cv2.resize(gray_face, (224,224))\n",
    "        gray_faces.append(gray_face)\n",
    "    return gray_faces, rects\n",
    "\n",
    "def find_embeddings(images):\n",
    "    \"\"\"\n",
    "    A function to find each face embeddings for the faces in each image\n",
    "    in @images\n",
    "\n",
    "    Args:\n",
    "        - images: a list of images\n",
    "    \"\"\"\n",
    "    images_embeddings = []\n",
    "    for image in images:\n",
    "        gray_faces, rectsss = find_faces(image)\n",
    "        for i, gray_face in enumerate(gray_faces):\n",
    "            cv2.imwrite(f'temp/{i}.jpg', gray_face)\n",
    "\n",
    "            gray_face = tf.io.read_file(f'temp/{i}.jpg')\n",
    "            gray_face = tf.image.decode_image(gray_face, channels=3)\n",
    "            gray_face = tf.image.resize(gray_face, (224,224))\n",
    "            gray_face = tf.cast(gray_face, tf.float32) / 255.0\n",
    "            gray_face = tf.expand_dims(gray_face, axis=0)\n",
    "\n",
    "            embeddings = siameseModel.siameseNetwork((gray_face, gray_face, gray_face))[0]\n",
    "            images_embeddings.append(embeddings)\n",
    "    return images_embeddings, rectsss\n",
    "\n",
    "def markAttendance(name):\n",
    "    \"\"\"\n",
    "    A function to marke attendance of the student @name\n",
    "\n",
    "    Args:\n",
    "        - name: the name of the student\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    fileName = \"attendance\" + str(now.date()) + \".csv\"\n",
    "    with open (fileName ,'a+') as f:\n",
    "        if os.stat(fileName).st_size == 0:\n",
    "            f.write(\"name, date\")\n",
    "        f.seek(0)\n",
    "        myDataList = f.readlines()\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(', ')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            dtstring = now.strftime('%H:%M:%S')\n",
    "            f.writelines(f'\\n{name}, {dtstring}') \n",
    "    filexlsm = \"attendance\" + str(now.date()) + \".xlsm\"      \n",
    "    merge_all_to_a_book(glob.glob(fileName), filexlsm)\n",
    "      \n",
    "\n",
    "#######################################\n",
    "# A list to save embeddings\n",
    "Path = IMAGES_PATH\n",
    "images = []\n",
    "ClassNames = []\n",
    "MyList = os.listdir(Path)\n",
    "print(MyList)\n",
    "for cl in MyList:\n",
    "    curImg = cv2.imread(f'{Path}/{cl}')\n",
    "    images.append(curImg)\n",
    "    ClassNames.append(os.path.splitext(cl)[0])\n",
    "print(ClassNames)\n",
    "students_embedding, _ =  find_embeddings(images)\n",
    "arrivals_embedding = []\n",
    "matched_index = -1\n",
    "# print(\"Length of students embeddings: \", len(students_embedding))\n",
    "\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "sleep(2)\n",
    "\n",
    "while True:\n",
    "    img = vs.read()\n",
    "    img = imutils.resize(img, width=500)\n",
    "    matchName = []\n",
    "    matchDist = []\n",
    "    matchIndex = []\n",
    "    arrivals_embedding, rect = find_embeddings([img])\n",
    "\n",
    "    for j, arrival_embedding in enumerate(arrivals_embedding):\n",
    "        for i, student_embedding in enumerate(students_embedding):\n",
    "            distance = tf.reduce_sum(tf.square(student_embedding - arrival_embedding), axis=-1)\n",
    "            distance = float(distance[0])\n",
    "            print(f\"The disctance with {ClassNames[i]} is:\", distance)\n",
    "            if distance < 0.20:\n",
    "                matchName.append(ClassNames[i].upper())\n",
    "                matchDist.append(distance)\n",
    "                matchIndex.append(rect[j])\n",
    "        if len(matchDist) != 0:    \n",
    "                Dist = min(matchDist)\n",
    "                # print (Dist)\n",
    "                index = matchDist.index(Dist)\n",
    "                (x, y, w, h) = rect[j]\n",
    "                name = matchName[index]\n",
    "                y1, x2, y2, x1 = y, (y + h) + 50, x + 170, (x + w) - 200\n",
    "                cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
    "                cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "                markAttendance(name)\n",
    "                print (name)\n",
    "\n",
    "    cv2.imshow(\"WebCam\",img)\n",
    "    k = cv2.waitKey(100)\n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "vs.stream.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
